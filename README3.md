# Вычислительные характеристики алгоритмов сортировки и поиска

---

## 1. Сортировка выбором (Selection Sort)

### Основная идея
На каждом шаге из неотсортированной части массива выбирается минимальный элемент и меняется местами с первым элементом этой части.

### Характеристики выполнения
- Внешний цикл: `for (i = 0; i < n - 1; i++)` — определяет начало неотсортированной части.  
- Внутренний цикл: `for (j = i + 1; j < n; j++)` — ищет индекс минимального элемента в оставшейся части.  
- После завершения внутреннего цикла происходит обмен элемента `arr[i]` с найденным минимальным.

### Трудоёмкость
- **Худший / средний / лучший случаи:** `O(n²)`  
- **Обоснование:** Алгоритм содержит два вложенных цикла. Общее число сравнений — `n(n − 1)/2`, что даёт квадратичную зависимость от размера массива.

---

## 2. Сортировка обменом (пузырёк, Bubble Sort)

### Основная идея
Многократные проходы по массиву с попарным сравнением соседних элементов и их обменом при нарушении порядка. На каждом проходе наибольший элемент «всплывает» в конец.

### Характеристики выполнения
- Внешний цикл: `for (i = 0; i < n - 1; i++)` — контролирует количество проходов.  
- Внутренний цикл на `i`-й итерации: `for (j = 0; j < n - i - 1; j++)` — сравнивает соседние элементы и выполняет обмен при необходимости.  
- При отсутствии обменов можно завершить досрочно.

### Трудоёмкость
- **Худший / средний случаи:** `O(n²)`  
- **Лучший случай (массив уже отсортирован):** `O(n)`  
- **Обоснование:** В худшем случае — `n(n − 1)/2` сравнений и до `3·n(n − 1)/2` операций присваивания (включая временную переменную). При упорядоченном массиве достаточно `n − 1` сравнений без обменов.

---

## 3. Сортировка вставками (Insertion Sort)

### Основная идея
Постепенное расширение отсортированной части массива за счёт вставки каждого следующего элемента в правильную позицию среди уже обработанных.

### Характеристики выполнения
- Внешний цикл: `for (i = 1; i < n; i++)` — перебирает элементы, начиная со второго.  
- Внутренний цикл: `while (j >= 0 && arr[j] > key)` — сдвигает элементы вправо, освобождая место для вставки.  
- Текущий элемент сохраняется во временной переменной (`key`).

### Трудоёмкость
- **Худший / средний случаи:** `O(n²)`  
- **Лучший случай:** `O(n)`  
- **Обоснование:** В худшем случае общее число сравнений — `n(n − 1)/2`, а присваиваний — `n(n + 1)/2 − 1`. Эффективность сильно зависит от начальной упорядоченности данных.

---

## 4. Сортировка слиянием (Merge Sort)

### Основная идея
Рекурсивное деление массива пополам до единичных элементов с последующим слиянием отсортированных частей. Применяется стратегия «разделяй и властвуй».

### Характеристики выполнения
- Рекурсивные вызовы заменяют внешний цикл: `mergeSort(left, mid)` и `mergeSort(mid + 1, right)`.  
- На каждом уровне рекурсии обрабатывается ровно `n` элементов.  
- Для слияния используется дополнительный буфер размером `O(n)`.

### Детали реализации (`mergeSort`)
- Проверка базового случая: `if (arr.length < 2)`  
- Вычисление середины: `int mid = arr.length / 2`  
- Создание подмассивов: `new int[mid]`, `new int[arr.length − mid]`  
- Копирование: `System.arraycopy(...)`  
- Рекурсивные вызовы и слияние

### Трудоёмкость
- **Худший / средний / лучший случаи:** `Θ(n log n)`  
- **Пространственная сложность:** `O(n)`  
- **Преимущества:** гарантированная эффективность, устойчивость (сохраняет порядок равных элементов), подходит для внешней сортировки.

---

## 5. Сортировка Шелла (Shell Sort)

### Основная идея
Модификация сортировки вставками, при которой элементы сравниваются и перемещаются с шагом (`gap`), который постепенно уменьшается до 1.

### Характеристики выполнения
- Внешний цикл уменьшает `gap`: `for (gap = n/2; gap > 0; gap /= 2)` — задаёт последовательность промежутков.  
- Внутренний цикл: `for (i = gap; i < n; i++)` — перебирает элементы, начиная с первого за пределами шага.  
- Вложенный цикл сдвига: `while (j >= gap && arr[j − gap] > temp)` — вставляет элемент в правильную позицию внутри подпоследовательности.

### Трудоёмкость
- **Зависит от последовательности шагов:**
  - Классическая: `O(n²)`
  - Последовательность Кнута: `O(n^(3/2))`
  - Оптимальные последовательности: `O(n log n)`
- **Обоснование:** Число проходов — `O(log n)`, но объём работы на каждом проходе зависит от шага. Эффективность сильно варьируется в зависимости от стратегии выбора интервалов.

---

## 6. Быстрая сортировка (Quick Sort)

### Основная идея
Выбор опорного элемента и разделение массива на две части: элементы меньше опоры — слева, больше — справа. Далее — рекурсивная сортировка подмассивов.

### Характеристики выполнения
- Рекурсивные вызовы заменяют внешний цикл: `quickSort(arr, low, pi - 1)` и `quickSort(arr, pi + 1, high)`.  
- Процедура `partition` перестраивает массив за `O(n)`.  
- Глубина рекурсии: от `log₂ n` (сбалансированное разбиение) до `n` (вырожденный случай).  
- В методичке используется последний элемент как опора.

### Трудоёмкость
- **Средний случай:** `O(n log n)`  
- **Худший случай (например, отсортированный массив):** `O(n²)`  
- **Лучший случай (идеальное разбиение):** `O(n log n)`  
- **Обоснование:** При неудачном выборе опоры разбиение становится вырожденным, и глубина рекурсии достигает `n`.

---

## 7. Пирамидальная сортировка (Heapsort)

### Основная идея
Построение max-heap из массива, затем последовательное извлечение максимального элемента и его перемещение в конец.

### Характеристики выполнения
- Внешний цикл: `for (i = n - 1; i > 0; i--)` — извлекает корень и перемещает его в конец.  
- Внутренний процесс: `heapify(arr, i, 0)` — восстанавливает свойство кучи после извлечения.  
- Первый этап — построение кучи за `O(n)`.  
- Работает in-place (дополнительная память — `O(1)`).

### Детали реализации
- Построение кучи начинается с индекса `⌊n/2⌋ − 1`  
- Функция `heapify` восстанавливает свойство кучи  
- Сортировка завершается после `n − 1` обменов

### Трудоёмкость
- **Худший / средний / лучший случаи:** `Θ(n log n)`  
- **Обоснование:** Глубина кучи — `⌈log₂ n⌉`; каждое извлечение требует `O(log n)` операций.  
- **Недостаток:** алгоритм неустойчив и не использует преимущества частичной упорядоченности.

---

## 8. Последовательный (линейный) поиск

### Основная идея
Перебор элементов массива по порядку с сравнением каждого с искомым значением.

### Характеристики выполнения
- Единственный цикл: `for (i = 0; i < n; i++)` — последовательно проверяет каждый элемент.  
- При нахождении совпадения возвращает индекс и завершает работу.  
- Работает с неотсортированными данными.

### Трудоёмкость
- **Все случаи:** `O(n)`  
- **Пространственная сложность:** `O(1)`

---

## 9. Бинарный (дихотомический) поиск

### Основная идея
Поиск в отсортированном массиве путём многократного деления области поиска пополам.

### Характеристики выполнения
- Цикл: `while (left <= right)` — управляет границами поиска.  
- На каждой итерации вычисляется середина: `mid = left + (right − left) / 2`  
- Границы корректируются в зависимости от результата сравнения.

### Трудоёмкость
- **Худший / средний случаи:** `O(log n)`  
- **Лучший случай:** `O(1)`  
- **Обоснование:** Размер области поиска уменьшается вдвое на каждом шаге. Максимум `⌈log₂(n + 1)⌉` итераций.

---

## 10. Интерполирующий поиск

### Основная идея
Уточнённый поиск в отсортированном массиве с использованием линейной интерполяции для оценки позиции искомого элемента.

### Формула позиции:
\[
pos = lo + \frac{(x - arr[lo]) \cdot (hi - lo)}{arr[hi] - arr[lo]}
\]

### Характеристики выполнения
- Цикл: `while (lo <= hi && x >= arr[lo] && x <= arr[hi])` — продолжает поиск, пока значение находится в диапазоне.  
- Позиция вычисляется по приведённой формуле.  
- Особенно эффективен при **равномерном распределении** значений.

### Трудоёмкость
- **При равномерном распределении:** `O(log log n)`  
- **В худшем случае:** `O(n)`  
- **Лучший случай:** `O(1)`  
- **Обоснование:** Область поиска сокращается экспоненциально при равномерных данных.

---

## 11. Поиск по числам Фибоначчи

### Основная идея
Аналог бинарного поиска, но деление массива происходит в пропорциях, задаваемых числами Фибоначчи (близко к золотому сечению).

### Характеристики выполнения
- Используются три последовательных числа Фибоначчи: `F(m)`, `F(m−1)`, `F(m−2)`  
- Основной цикл: `while (offset < n)` — сравнивает `arr[offset + fib_m2]` с целью.  
- Не требует операций умножения/деления — только сложение и вычитание.

### Трудоёмкость
- **Все случаи:** `O(log n)`  
- **Обоснование:** Количество итераций пропорционально индексу `k`, где `F(k) ≥ n`. Поскольку `F(k) ≈ φ^k / √5` (φ ≈ 1.618), то `k ≈ 1.44·log₂ n`.

---

> **Заключение**  
> Анализ показал, что алгоритмы с гарантированной сложностью `O(n log n)` (слиянием, пирамидальная) предпочтительны при работе с большими или неизвестными по структуре данными. Алгоритмы с квадратичной сложностью (`O(n²)`) могут быть приемлемы только для небольших массивов. Среди методов поиска бинарный и интерполирующий обеспечивают значительное ускорение по сравнению с линейным, но требуют предварительной сортировки.
